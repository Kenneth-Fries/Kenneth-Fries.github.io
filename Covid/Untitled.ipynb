{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "import numpy\n",
    "import json\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = \"C:/Program Files/PostgreSQL/12/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Engine\n",
    "engine = create_engine('postgresql://postgres:Qd4+typo@localhost/Covid19')\n",
    "\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['locationid',\n",
       " 'date',\n",
       " 'deaths',\n",
       " 'confirmed',\n",
       " '7_day_daily_avg_confirmed',\n",
       " '7_day_daily_avg_deaths',\n",
       " 'index',\n",
       " 'locationid',\n",
       " 'country',\n",
       " 'state',\n",
       " 'county',\n",
       " 'iso2',\n",
       " 'iso3',\n",
       " 'population',\n",
       " 'code3',\n",
       " 'fips',\n",
       " 'lattitude',\n",
       " 'longitude',\n",
       " 'location']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pd.read_sql(\"SELECT * FROM data JOIN locations on data.LocationID = locations.LocationID\", conn).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_deaths = \"https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv\"\n",
    "url_confirmed = \"https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\"\n",
    "\n",
    "\n",
    "\n",
    "df_deaths = pd.read_csv(url_deaths)\n",
    "df_confirmed = pd.read_csv(url_confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths.fillna(0, inplace=True)\n",
    "df_confirmed.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado',\n",
    "         'Connecticut','Delaware','Florida','Georgia','Hawaii','Idaho', \n",
    "         'Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana',\n",
    "         'Maine' 'Maryland','Massachusetts','Michigan','Minnesota',\n",
    "         'Mississippi', 'Missouri','Montana','Nebraska','Nevada',\n",
    "         'New Hampshire','New Jersey','New Mexico','New York',\n",
    "         'North Carolina','North Dakota','Ohio',    \n",
    "         'Oklahoma','Oregon','Pennsylvania','Rhode Island',\n",
    "         'South  Carolina','South Dakota','Tennessee','Texas','Utah',\n",
    "         'Vermont','Virginia','Washington','West Virginia',\n",
    "         'Wisconsin','Wyoming']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UID',\n",
       " 'iso2',\n",
       " 'iso3',\n",
       " 'code3',\n",
       " 'FIPS',\n",
       " 'Admin2',\n",
       " 'Province_State',\n",
       " 'Country_Region',\n",
       " 'Lat',\n",
       " 'Long_',\n",
       " 'Combined_Key',\n",
       " 'Population']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_deaths.columns[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationid</th>\n",
       "      <th>date</th>\n",
       "      <th>deaths</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>confirmed7avg</th>\n",
       "      <th>deaths7avg</th>\n",
       "      <th>location_id</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>population</th>\n",
       "      <th>code3</th>\n",
       "      <th>fips</th>\n",
       "      <th>lattitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [locationid, date, deaths, confirmed, confirmed7avg, deaths7avg, location_id, country, state, county, iso2, iso3, population, code3, fips, lattitude, longitude, location]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_df = pd.DataFrame(columns=list(pd.read_sql(\"SELECT * FROM data JOIN locations on LocationID = LocationID\", conn).columns))\n",
    "sql_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASM</td>\n",
       "      <td>16</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>US</td>\n",
       "      <td>-14.271000</td>\n",
       "      <td>-170.132000</td>\n",
       "      <td>American Samoa, US</td>\n",
       "      <td>55641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>GU</td>\n",
       "      <td>GUM</td>\n",
       "      <td>316</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Guam</td>\n",
       "      <td>US</td>\n",
       "      <td>13.444300</td>\n",
       "      <td>144.793700</td>\n",
       "      <td>Guam, US</td>\n",
       "      <td>164229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>580</td>\n",
       "      <td>MP</td>\n",
       "      <td>MNP</td>\n",
       "      <td>580</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "      <td>US</td>\n",
       "      <td>15.097900</td>\n",
       "      <td>145.673900</td>\n",
       "      <td>Northern Mariana Islands, US</td>\n",
       "      <td>55144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>630</td>\n",
       "      <td>PR</td>\n",
       "      <td>PRI</td>\n",
       "      <td>630</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>18.220800</td>\n",
       "      <td>-66.590100</td>\n",
       "      <td>Puerto Rico, US</td>\n",
       "      <td>2933408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>VI</td>\n",
       "      <td>VIR</td>\n",
       "      <td>850</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin Islands</td>\n",
       "      <td>US</td>\n",
       "      <td>18.335800</td>\n",
       "      <td>-64.896300</td>\n",
       "      <td>Virgin Islands, US</td>\n",
       "      <td>107268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3256</td>\n",
       "      <td>84070016</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Central Utah</td>\n",
       "      <td>Utah</td>\n",
       "      <td>US</td>\n",
       "      <td>39.372319</td>\n",
       "      <td>-111.575868</td>\n",
       "      <td>Central Utah, Utah, US</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3257</td>\n",
       "      <td>84070017</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Southeast Utah</td>\n",
       "      <td>Utah</td>\n",
       "      <td>US</td>\n",
       "      <td>38.996171</td>\n",
       "      <td>-110.701396</td>\n",
       "      <td>Southeast Utah, Utah, US</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3258</td>\n",
       "      <td>84070018</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Southwest Utah</td>\n",
       "      <td>Utah</td>\n",
       "      <td>US</td>\n",
       "      <td>37.854472</td>\n",
       "      <td>-111.441876</td>\n",
       "      <td>Southwest Utah, Utah, US</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3259</td>\n",
       "      <td>84070019</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TriCounty</td>\n",
       "      <td>Utah</td>\n",
       "      <td>US</td>\n",
       "      <td>40.124915</td>\n",
       "      <td>-109.517442</td>\n",
       "      <td>TriCounty, Utah, US</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>84070020</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Weber-Morgan</td>\n",
       "      <td>Utah</td>\n",
       "      <td>US</td>\n",
       "      <td>41.271160</td>\n",
       "      <td>-111.914512</td>\n",
       "      <td>Weber-Morgan, Utah, US</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3261 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           UID iso2 iso3  code3  FIPS          Admin2  \\\n",
       "0           16   AS  ASM     16  60.0               0   \n",
       "1          316   GU  GUM    316  66.0               0   \n",
       "2          580   MP  MNP    580  69.0               0   \n",
       "3          630   PR  PRI    630  72.0               0   \n",
       "4          850   VI  VIR    850  78.0               0   \n",
       "...        ...  ...  ...    ...   ...             ...   \n",
       "3256  84070016   US  USA    840   0.0    Central Utah   \n",
       "3257  84070017   US  USA    840   0.0  Southeast Utah   \n",
       "3258  84070018   US  USA    840   0.0  Southwest Utah   \n",
       "3259  84070019   US  USA    840   0.0       TriCounty   \n",
       "3260  84070020   US  USA    840   0.0    Weber-Morgan   \n",
       "\n",
       "                Province_State Country_Region        Lat       Long_  \\\n",
       "0               American Samoa             US -14.271000 -170.132000   \n",
       "1                         Guam             US  13.444300  144.793700   \n",
       "2     Northern Mariana Islands             US  15.097900  145.673900   \n",
       "3                  Puerto Rico             US  18.220800  -66.590100   \n",
       "4               Virgin Islands             US  18.335800  -64.896300   \n",
       "...                        ...            ...        ...         ...   \n",
       "3256                      Utah             US  39.372319 -111.575868   \n",
       "3257                      Utah             US  38.996171 -110.701396   \n",
       "3258                      Utah             US  37.854472 -111.441876   \n",
       "3259                      Utah             US  40.124915 -109.517442   \n",
       "3260                      Utah             US  41.271160 -111.914512   \n",
       "\n",
       "                      Combined_Key  Population  \n",
       "0               American Samoa, US       55641  \n",
       "1                         Guam, US      164229  \n",
       "2     Northern Mariana Islands, US       55144  \n",
       "3                  Puerto Rico, US     2933408  \n",
       "4               Virgin Islands, US      107268  \n",
       "...                            ...         ...  \n",
       "3256        Central Utah, Utah, US           0  \n",
       "3257      Southeast Utah, Utah, US           0  \n",
       "3258      Southwest Utah, Utah, US           0  \n",
       "3259           TriCounty, Utah, US           0  \n",
       "3260        Weber-Morgan, Utah, US           0  \n",
       "\n",
       "[3261 rows x 12 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deaths[df_deaths.columns[:12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_cases = {}                                  #make dictionary for all data\n",
    "countries = df_deaths.Country_Region.unique()     #get list of countries\n",
    "\n",
    "for country in countries:                         #If multiple countries\n",
    "    states = df_deaths.Province_State.unique()\n",
    "    \n",
    "    covid_cases.update({country:{}})              #Add the new country name and create a sub-dict\n",
    "    \n",
    "    for state in states:\n",
    "        if state in states_list:\n",
    "            state_df = df_deaths[df_deaths.Province_State == state]\n",
    "            counties = state_df.Admin2.to_list()\n",
    "            covid_cases[country].update({state:{}})\n",
    "            \n",
    "            for county in counties:\n",
    "                df = state_df[state_df.Admin2 == county].T[12:]    #columns start at 12 with one datapoint per column\n",
    "                                                                #Transpose date columns to row index\n",
    "                #df.index = pd.to_datetime(df.index)                #Set row index to datetime\n",
    "                county_data = df.diff(1).fillna(0)                 #Find delta\n",
    "                \n",
    "                county_smoothed_7day = df.diff(7).fillna(0) / 7    #Find 7 day avg delta\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                iso2 = state_df.iso2[state_df.Admin2 == county].values[0]    #State Abbreviation\n",
    "                population = state_df.Population[state_df.Admin2 == county].values[0]   # population\n",
    "                covid_cases[country][state].update({\n",
    "                                                county:{\n",
    "                                                    \"lat\" : str(state_df[state_df.Admin2 == county].Lat.values[0]),\n",
    "                                                    \"long\" : str(state_df[state_df.Admin2 == county].Long_.values[0]),\n",
    "                                                    \"deaths\" : [],\n",
    "                                                    \"deaths_7_day\" : [],\n",
    "                                                    \"dates\" : [],\n",
    "                                                    \"abbreviation\": iso2,\n",
    "                                                    \"population\": str(population)\n",
    "                                            }})\n",
    "                for m, y in enumerate(county_data):\n",
    "                    for x in list(zip(county_data[y].index, county_data[y].values)):\n",
    "                        covid_cases[country][state][county]['deaths'].append(int(x[1]))\n",
    "                        covid_cases[country][state][county]['dates'].append(x[0])\n",
    "                        \n",
    "                for m, y in enumerate(county_smoothed_7day):\n",
    "                    for x in list(zip(county_smoothed_7day[y].index, county_smoothed_7day[y].values)):\n",
    "                        if covid_cases[country][state][county]['dates'][m] == x[0]:\n",
    "                            covid_cases[country][state][county]['deaths_7_day'].append(int(x[1]))\n",
    "                            \n",
    "                                                                            \n",
    " \n",
    "\n",
    "\n",
    "countries = df_confirmed.Country_Region.unique()\n",
    "for country in countries:\n",
    "    print(country, \"{\")\n",
    "    states = df_confirmed.Province_State.unique()\n",
    "    \n",
    "    for n, state  in enumerate(states):\n",
    "        if state in states_list:\n",
    "\n",
    "            \n",
    "            if n < 60:      # Useful for allowing only a few states to run.\n",
    "                state_df = df_confirmed[df_confirmed.Province_State == state]\n",
    "                counties = state_df.Admin2.to_list()\n",
    "                print(\"    \", state, \" #\", len(counties), \" counties.\")\n",
    "                for county in counties:\n",
    "                    df = state_df[state_df.Admin2 == county].T[11:]    #columns start at 12 with one datapoint per column\n",
    "                                                                    #Transpose date columns to row index\n",
    "                    #df.index = pd.to_datetime(df.index)                #Set row index to datetime\n",
    "                    county_data = df.diff(1).fillna(0)                 #Find delta\n",
    "                    county_smoothed_7day = df.diff(7).fillna(0) / 7    #Find 7 day avg delta\n",
    "                    iso2 = state_df.iso2[state_df.Admin2 == county]\n",
    "                    \n",
    "                    covid_cases[country][state][county].update({\n",
    "                            \"confirmed\" : [],\n",
    "                            \"confirmed_7_day\" : [],\n",
    "                            \"county_name_check\" : county\n",
    "                            })\n",
    "                    for m, y in enumerate(county_data):\n",
    "                        for x in list(zip(county_data[y].index, county_data[y].values)):\n",
    "                            covid_cases[country][state][county]['confirmed'].append(int(x[1]))    \n",
    "                            \n",
    "                    for m, y in enumerate(county_smoothed_7day):\n",
    "                        for x in list(zip(county_smoothed_7day[y].index, county_smoothed_7day[y].values)):\n",
    "                            covid_cases[country][state][county]['confirmed_7_day'].append(int(x[1]))    \n",
    "                    \n",
    "    \n",
    "\n",
    "\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(covid_cases, fp)\n",
    "\n",
    "print(\"Finished \" )\n",
    "\n",
    "print(df_deaths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
